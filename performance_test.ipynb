{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe50ec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import src.misc.dist as dist \n",
    "from src.core import YAMLConfig \n",
    "from src.solver import TASKS\n",
    "from src.zoo.rtdetr.box_ops import box_cxcywh_to_xyxy as rtdetr_box_cxcywh_to_xyxy\n",
    "\n",
    "np.random.seed(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f9c10ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load PResNet50 state_dict\n",
      "Tuning checkpoint from rtdetr_r50vd_6x_coco_from_paddle.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hust master thesis\\codes\\rtdetr_pytorch\\src\\solver\\solver.py:148: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model.state_dict, {'missed': [], 'unmatched': []}\n",
      "Tuning checkpoint from rtdetr_r50vd_6x_coco_from_paddle.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hust master thesis\\codes\\rtdetr_pytorch\\src\\core\\yaml_utils.py:148: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  return cls(**cls_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model.state_dict, {'missed': [], 'unmatched': []}\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ABC\\.conda\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.93s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Namespace(\n",
    "                config='configs/rtdetr/rtdetr_r50vd_6x_coco_customed.yml', \n",
    "                # config='configs/rtdetr/rtdetr_r50vd_6x_coco.yml', \n",
    "                resume=None, \n",
    "                tuning='rtdetr_r50vd_6x_coco_from_paddle.pth', \n",
    "                test_only=True, \n",
    "                amp=True, \n",
    "                seed=0)\n",
    "\n",
    "cfg = YAMLConfig(\n",
    "    args.config,\n",
    "    resume=args.resume, \n",
    "    use_amp=args.amp,\n",
    "    tuning=args.tuning\n",
    ")\n",
    "\n",
    "solver = TASKS[cfg.yaml_cfg['task']](cfg)\n",
    "solver.setup()\n",
    "solver.eval()\n",
    "solver.model.eval()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91a69146",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256  # Kích thước embedding\n",
    "num_heads = 8    # Số lượng head\n",
    "bs = 4   # Kích thước batch\n",
    "seq_len_q = 300   # Độ dài chuỗi query\n",
    "seq_len_kv = 300  # Độ dài chuỗi key/value\n",
    "dropout = 0.1    # Tỷ lệ dropout\n",
    "\n",
    "query = torch.ones(bs, seq_len_q, embed_dim, device=solver.device)  # (N, L, E)\n",
    "key = torch.ones(bs, seq_len_kv, embed_dim, device=solver.device)  # (N, S, E)\n",
    "value = torch.ones(bs, seq_len_kv, embed_dim, device=solver.device)  # (N, S, E)\n",
    "\n",
    "# Tạo mask cho query\n",
    "query_mask = torch.zeros((bs, num_heads, seq_len_q), dtype=torch.bool, device=solver.device) # [bs, nhead, num_queries]\n",
    "query_mask[..., 150:] = True\n",
    "\n",
    "query_attn_mask = query_mask.unsqueeze(-1) | query_mask.unsqueeze(-2) # [bs, nhead, num_queries, num_queries]\n",
    "query_attn_mask = query_attn_mask.reshape(-1, seq_len_q, seq_len_q)  # [bs * nhead, num_queries, num_queries]\n",
    "\n",
    "query_attn_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928e5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.zoo.rtdetr.customed_decoder3 import FlashMultiheadAttention\n",
    "\n",
    "\n",
    "flash_attn = FlashMultiheadAttention(\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_heads,\n",
    "    dropout=dropout,\n",
    "    bias=True,\n",
    "    batch_first=True,\n",
    "    device=solver.device,\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbcca2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average forward pass time: 0.001153 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "iterations = 1000\n",
    "# Thực hiện forward pass và đo thời gian\n",
    "for _ in range(iterations):\n",
    "    torch.cuda.synchronize()  # Đảm bảo GPU đã sẵn sàng\n",
    "    start_time = time.time()\n",
    "    # Forward pass\n",
    "    output, _ = flash_attn(\n",
    "        query=query,\n",
    "        key=key,\n",
    "        value=value,\n",
    "        key_padding_mask=None,  # Có thể thêm key_padding_mask nếu cần\n",
    "        need_weights=False,\n",
    "        attn_mask=query_attn_mask,  # Sử dụng mask đã tạo\n",
    "        is_causal=False  # Đặt False vì đã cung cấp mask\n",
    "    )\n",
    "    torch.cuda.synchronize()  # Đảm bảo GPU đã hoàn thành\n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "avg_time = total_time / iterations\n",
    "print(f\"Average forward pass time: {avg_time:.6f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
